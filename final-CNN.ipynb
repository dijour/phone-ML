{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Media Activity Recognition\n",
    "The goal is to develop a machine learning pipeline to recognize different social media usage using an iPhone’s motion sensors (accelerometer, gyroscope, etc).\n",
    "\n",
    "#### Activities\n",
    "1. Instagram\n",
    "2. Tinder\n",
    "3. Facebook\n",
    "4. LinkedIn\n",
    "5. Notetaking/texting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# essentials\n",
    "import numpy as np # used for handling numbers\n",
    "import scipy as sc\n",
    "import pandas as pd # used for handling the dataset\n",
    "import os # to get csv files of data\n",
    "\n",
    "from sklearn.model_selection import KFold, GroupKFold, cross_val_score, train_test_split\n",
    "from sklearn.impute import SimpleImputer # used for handling missing data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder # used for encoding categorical data\n",
    "from sklearn.preprocessing import StandardScaler # used for feature scaling\n",
    "\n",
    "# classifiers \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# neural networks\n",
    "import tensorflow as t # for RNN\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# analysis\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loads the sensor data from numpy files.\n",
    "### First, manually filter each CSV to remove any rows where Light > 100, to ensure that the data is only from when phone was in pocket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(base_folder, activity, convert_to_numpy=True):\n",
    "    out = []\n",
    "    file_names = os.listdir('%s/%s' %(base_folder, activity))\n",
    "    for file in file_names:\n",
    "        if (file == '.DS_Store'):\n",
    "            continue\n",
    "        data = pd.read_csv(('%s/%s/'+file) % (base_folder, activity),\n",
    "                            usecols=[\n",
    "                                    'loggingTime(txt)',\n",
    "                                    'loggingSample(N)', # this is easier to filter beginning/end frames\n",
    "                                    'locationLatitude(WGS84)',\n",
    "                                    'locationLongitude(WGS84)',\n",
    "                                    'locationAltitude(m)',\n",
    "                                    'locationSpeed(m/s)',\n",
    "#                                     'locationCourse(¬∞)',\n",
    "#                                     'locationHeadingX(¬µT)',\n",
    "#                                     'locationHeadingY(¬µT)',\n",
    "#                                     'locationHeadingZ(¬µT)',\n",
    "#                                     'locationTrueHeading(¬∞)',\n",
    "#                                     'locationMagneticHeading(¬∞)',\n",
    "                                    'accelerometerAccelerationX(G)',\n",
    "                                    'accelerometerAccelerationY(G)',\n",
    "                                    'accelerometerAccelerationZ(G)',\n",
    "                                    'gyroRotationX(rad/s)',\n",
    "                                    'gyroRotationY(rad/s)',\n",
    "                                    'gyroRotationZ(rad/s)',\n",
    "#                                     'magnetometerX(¬µT)',\n",
    "#                                     'magnetometerY(¬µT)',\n",
    "#                                     'magnetometerZ(¬µT)',\n",
    "                                    'motionYaw(rad)',\n",
    "                                    'motionRoll(rad)',\n",
    "                                    'motionPitch(rad)',\n",
    "                                    'motionRotationRateX(rad/s)',\n",
    "                                    'motionRotationRateY(rad/s)',\n",
    "                                    'motionRotationRateZ(rad/s)',\n",
    "                                    'motionUserAccelerationX(G)',\n",
    "                                    'motionUserAccelerationY(G)',\n",
    "                                    'motionUserAccelerationZ(G)',\n",
    "                                    'motionQuaternionX(R)',\n",
    "                                    'motionQuaternionY(R)',\n",
    "                                    'motionQuaternionZ(R)',\n",
    "                                    'motionQuaternionW(R)',\n",
    "                                    'motionGravityX(G)',\n",
    "                                    'motionGravityY(G)',\n",
    "                                    'motionGravityZ(G)',\n",
    "#                                     'motionMagneticFieldX(¬µT)',\n",
    "#                                     'motionMagneticFieldY(¬µT)',\n",
    "#                                     'motionMagneticFieldZ(¬µT)',\n",
    "                                    'altimeterRelativeAltitude(m)',\n",
    "                                    'altimeterPressure(kPa)',\n",
    "                                    'deviceOrientation(Z)',\n",
    "                                    'avAudioRecorderPeakPower(dB)',\n",
    "                                    'avAudioRecorderAveragePower(dB)']\n",
    "                          )\n",
    "        data = filter_input(data)\n",
    "        \n",
    "        if convert_to_numpy:\n",
    "            out.append(data.to_numpy())\n",
    "        else:\n",
    "            out.append(data)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This particular cell of code was taken from:\n",
    "# https://github.com/KChen89/Accelerometer-Filtering/blob/master/acc.py\n",
    "#\n",
    "# This does median filtering to reduce noise for acc. and gyro data\n",
    "# Ignore this unless u want to understand implementation of plotting commented out in the next cell\n",
    "import math\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# creates a median filter on data\n",
    "def median_filter(data, f_size):\n",
    "    lgth, num_signal=data.shape\n",
    "    f_data=np.zeros([lgth, num_signal])\n",
    "    \n",
    "    for i in range(num_signal):\n",
    "        f_data[:,i]=signal.medfilt(data[:,i], f_size)\n",
    "    return f_data\n",
    "\n",
    "# creates a frequency filter on data\n",
    "def freq_filter(data, f_size, cutoff):\n",
    "    lgth, num_signal=data.shape\n",
    "    f_data=np.zeros([lgth, num_signal])\n",
    "    lpf=signal.firwin(f_size, cutoff, window='hamming')\n",
    "    for i in range(num_signal):\n",
    "        f_data[:,i]=signal.convolve(data[:,i], lpf, mode='same')\n",
    "    return f_data\n",
    "\n",
    "# creates a fast fourier transform plot on data\n",
    "def fft_plot(data, fs, title):\n",
    "    lgth, num_signal=data.shape\n",
    "    fqy=np.zeros([lgth,num_signal])\n",
    "    fqy[:,0]=np.abs(fft(data[:,0]))\n",
    "    fqy[:,1]=np.abs(fft(data[:,1]))\n",
    "    fqy[:,2]=np.abs(fft(data[:,2]))\n",
    "    index=np.arange(int(lgth/2))/(int(lgth/2)/(fs/2))\n",
    "    \n",
    "    fig, ax=plt.subplots()\n",
    "    labels=['x','y','z']\n",
    "    color_map=['r', 'g', 'b']\n",
    "    for i in range(3):\n",
    "        ax.plot(index, fqy[0:int(lgth/2),i], color_map[i], label=labels[i])\n",
    "    ax.set_xlim([0, fs/2])\n",
    "    ax.set_xlabel('Hz')\n",
    "    ax.set_title('Frequency spectrum: '+title) \n",
    "    ax.legend()\n",
    "\n",
    "# plots lines! Wooo\n",
    "def plot_lines(data, fs, title):\n",
    "    num_rows, num_cols=data.shape\n",
    "    if num_cols!=3:\n",
    "        raise ValueError('Not 3D data')\n",
    "        \n",
    "    fig, ax=plt.subplots()\n",
    "    labels=['x','y','z']\n",
    "    color_map=['r', 'g', 'b']\n",
    "    index=np.arange(num_rows)/fs\n",
    "    \n",
    "    for i in range(num_cols):\n",
    "        ax.plot(index, data[:,i], color_map[i], label=labels[i])\n",
    "    ax.set_xlim([0,num_rows/fs])\n",
    "    ax.set_xlabel('Time [sec]')\n",
    "    ax.set_title('Time domain: '+title)\n",
    "    ax.legend()\n",
    "\n",
    "# creates the 3D plot of our accelerometer/gyroscope data\n",
    "def plot3D(data, title):\n",
    "    fig=plt.figure()\n",
    "    ax=fig.add_subplot(111, projection='3d')\n",
    "    ax.plot(xs=data[:,0], ys=data[:,1], zs=data[:,2], zdir='z')\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful not to run the plots when loading all the data. Test it by loading just a file or group of files and uncomment after finished exploring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filters accelerometer or gyroscope data\n",
    "cutoff=10\n",
    "fs=512\n",
    "def filter_sensor(data, sensor_type):\n",
    "    if sensor_type == \"gyroscope\":\n",
    "        sensor_data = data.iloc[:,9:12].to_numpy()\n",
    "    else:\n",
    "        sensor_data = data.iloc[:,6:9].to_numpy()\n",
    "    \n",
    "#     median_data=median_filter(sensor_data, 155)\n",
    "    lpf_data=freq_filter(sensor_data, 155, cutoff/fs)\n",
    "#     comb_data=freq_filter(median_data, 155, cutoff/fs)\n",
    "    \n",
    "#     plot_lines(sensor_data, fs, 'Raw data')\n",
    "#     fft_plot(sensor_data, fs, 'Raw data')\n",
    "    \n",
    "#     plot_lines(median_data, fs, 'median filter')\n",
    "#     plot_lines(lpf_data, fs, 'low pass filter')\n",
    "#     plot_lines(comb_data, fs, 'median+low pass filter')\n",
    "    \n",
    "#     fft_plot(lpf_data, fs, 'low pass filter')\n",
    "#     fft_plot(median_data, fs, 'median filter')\n",
    "#     fft_plot(comb_data, fs, 'median+low pass filter')\n",
    "    \n",
    "#     plot3D(sensor_data, 'raw data')\n",
    "#     plot3D(median_data, 'median filter')\n",
    "#     plot3D(lpf_data, 'low pass filter')\n",
    "#     plot3D(comb_data, 'median+low pass filter')\n",
    "#     plt.show()\n",
    "    \n",
    "    if sensor_type == \"gyroscope\":\n",
    "        data.loc[:,'gyroRotationX(rad/s)'] = lpf_data[:,0]\n",
    "        data.loc[:,'gyroRotationY(rad/s)'] = lpf_data[:,1]\n",
    "        data.loc[:,'gyroRotationZ(rad/s)'] = lpf_data[:,2]\n",
    "    else:\n",
    "        data.loc[:,'accelerometerAccelerationX(G)'] = lpf_data[:,0]\n",
    "        data.loc[:,'accelerometerAccelerationY(G)'] = lpf_data[:,1]\n",
    "        data.loc[:,'accelerometerAccelerationZ(G)'] = lpf_data[:,2]\n",
    "    return data\n",
    "\n",
    "# X_tinder = load_data(\"samples\", \"facebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the first 2 seconds (60 rows), and last 1 second (30 rows)\n",
    "def filter_input(data):\n",
    "    data = data.iloc[60:-60,]\n",
    "    data = filter_sensor(data, \"accelerometer\")\n",
    "    data = filter_sensor(data, \"gyroscope\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of X samples: 167\n",
      "Total number of Y samples: 167\n"
     ]
    }
   ],
   "source": [
    "# Load the data for each class\n",
    "X_tinder = load_data(\"data\", \"tinder\")\n",
    "X_instagram = load_data(\"data\", \"instagram\")\n",
    "X_notes = load_data(\"data\", \"notes\")\n",
    "X_facebook = load_data(\"data\", \"facebook\")\n",
    "X_linkedin = load_data(\"data\", \"linkedin\")\n",
    "\n",
    "# Assigning groundtruth conditions to each class\n",
    "Y_tinder = [0] * len(X_tinder) \n",
    "Y_instagram = [1] * len(X_instagram)\n",
    "Y_notes = [2] * len(X_notes)\n",
    "Y_facebook = [3] * len(X_facebook)\n",
    "Y_linkedin = [4] * len(X_linkedin)\n",
    "\n",
    "X = np.concatenate((X_tinder, X_instagram, X_notes, X_facebook, X_linkedin)) # insert standing when done \n",
    "Y = np.concatenate((Y_tinder, Y_instagram, Y_notes, Y_facebook, Y_linkedin)) # insert standing when done\n",
    "print(\"Total number of X samples: \" + str(len(X)))\n",
    "print(\"Total number of Y samples: \" + str(len(Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facebook\n",
      "count    1936.000000\n",
      "mean        0.434090\n",
      "std         0.025280\n",
      "min         0.379947\n",
      "25%         0.413376\n",
      "50%         0.430085\n",
      "75%         0.450800\n",
      "max         0.495081\n",
      "Name: motionPitch(rad), dtype: float64\n",
      "\n",
      "instagram\n",
      "count    1644.000000\n",
      "mean        0.670083\n",
      "std         0.087409\n",
      "min         0.282256\n",
      "25%         0.647026\n",
      "50%         0.661296\n",
      "75%         0.718457\n",
      "max         1.000684\n",
      "Name: motionPitch(rad), dtype: float64\n",
      "\n",
      "linkedin\n",
      "count    1512.000000\n",
      "mean        0.566341\n",
      "std         0.083944\n",
      "min         0.412432\n",
      "25%         0.501860\n",
      "50%         0.566077\n",
      "75%         0.617322\n",
      "max         1.013837\n",
      "Name: motionPitch(rad), dtype: float64\n",
      "\n",
      "notes\n",
      "count    1654.000000\n",
      "mean        0.819122\n",
      "std         0.057150\n",
      "min         0.619680\n",
      "25%         0.780668\n",
      "50%         0.828112\n",
      "75%         0.855144\n",
      "max         0.971548\n",
      "Name: motionPitch(rad), dtype: float64\n",
      "\n",
      "tinder\n",
      "count    1901.000000\n",
      "mean        0.285155\n",
      "std         0.048023\n",
      "min         0.150253\n",
      "25%         0.250699\n",
      "50%         0.286083\n",
      "75%         0.321363\n",
      "max         0.432564\n",
      "Name: motionPitch(rad), dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "column_name = 'motionPitch(rad)' # replace me with other sensors!\n",
    "activities = ['facebook', 'instagram', 'linkedin', 'notes', 'tinder']\n",
    "\n",
    "for a in activities:\n",
    "    curr_data = load_data('samples', a, False)[0]\n",
    "    print(a)\n",
    "    print(curr_data[column_name].describe())\n",
    "    print('')\n",
    "    \n",
    "#     'accelerometerAccelerationX(G)',\n",
    "#     'accelerometerAccelerationY(G)',\n",
    "#     'accelerometerAccelerationZ(G)',\n",
    "#     'gyroRotationX(rad/s)',\n",
    "#     'gyroRotationY(rad/s)',\n",
    "#     'gyroRotationZ(rad/s)',\n",
    "#     'motionYaw(rad)',\n",
    "#     'motionRoll(rad)',\n",
    "#     'motionPitch(rad)',\n",
    "#     'motionRotationRateX(rad/s)',\n",
    "#     'motionRotationRateY(rad/s)',\n",
    "#     'motionRotationRateZ(rad/s)',\n",
    "#     'motionUserAccelerationX(G)',\n",
    "#     'motionUserAccelerationY(G)',\n",
    "#     'motionUserAccelerationZ(G)',\n",
    "#     'motionQuaternionX(R)',\n",
    "#     'motionQuaternionY(R)',\n",
    "#     'motionQuaternionZ(R)',\n",
    "#     'motionQuaternionW(R)',\n",
    "#     'motionGravityX(G)',\n",
    "#     'motionGravityY(G)',\n",
    "#     'motionGravityZ(G)',"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the norm/magnitude of a 3-axis sensor\n",
    "def calc_sensor_norm(sensor_x, sensor_y, sensor_z):\n",
    "    sensor_total = []\n",
    "    for i in range(len(sensor_x)):\n",
    "        sensor_total.append((sensor_x[i]**2 + sensor_y[i]**2 + sensor_z[i]**2)**5)\n",
    "    return sensor_total\n",
    "\n",
    "# window input data by seconds and overlap\n",
    "def window_input(input_data, seconds=1, overlap=0.5, hz=30):\n",
    "    data_len = len(input_data)\n",
    "    window_len = seconds*hz\n",
    "    overlap_len = int(window_len * (1-overlap))\n",
    "    frame_count = 0\n",
    "    windows, next_win = [], []\n",
    "    # create windows if fits; up to overlap_len - 1 frames removed from end\n",
    "    for i in range(data_len):\n",
    "        next_win.append(input_data[i])\n",
    "        frame_count += 1\n",
    "        if (frame_count % overlap_len == 0) and (len(next_win) == window_len):\n",
    "            windows.append(next_win.copy())\n",
    "            del next_win[:overlap_len]\n",
    "    windows = np.asarray(windows)\n",
    "    return np.asarray(windows)\n",
    "\n",
    "# create spectrogram data. If windowing, calculate FFT at 50% overlap; else use whole recording\n",
    "def process_input(X, Y, windowing):\n",
    "    x_out = []\n",
    "    y_out = []\n",
    "    groups = list([])\n",
    "    for i in range(len(X)):\n",
    "        if windowing:\n",
    "            windows = window_input(X[i], 2, 0.5, 30)\n",
    "            # featurize and add to output\n",
    "            for w in windows:\n",
    "                groups.append(i)\n",
    "                a_feat = featurize_input(w)\n",
    "                x_out.append(a_feat)\n",
    "                y_out.append(Y[i])\n",
    "        else:\n",
    "            groups.append(i)\n",
    "            w = featurize_input(X[i])\n",
    "            x_out.append(w)\n",
    "            y_out.append(Y[i])\n",
    "    return (np.asarray(x_out), np.asarray(y_out), np.asarray(groups))\n",
    "\n",
    "# Add bins as features or domain-specific features\n",
    "def featurize_input(sample):\n",
    "    fv = []\n",
    "    acc_x = sample[:,6]\n",
    "    acc_y = sample[:,7]\n",
    "    acc_z = sample[:,8]\n",
    "    acc_total = calc_sensor_norm(acc_x, acc_y, acc_z)\n",
    "    gyro_x = sample[:,9]\n",
    "    gyro_y = sample[:,10]\n",
    "    gyro_z = sample[:,11]\n",
    "    gyro_total = calc_sensor_norm(gyro_x, gyro_y, gyro_z)\n",
    "    loc_speed = sample[:,5]\n",
    "    altimeter = sample[:,28]\n",
    "    \n",
    "    motionYaw = sample[:,12]\n",
    "    fv.append(np.max(motionYaw))\n",
    "    fv.append(np.mean(motionYaw))\n",
    "    fv.append(np.std(motionYaw))\n",
    "    motionRoll = sample[:,13]\n",
    "    fv.append(np.max(motionRoll))\n",
    "    fv.append(np.mean(motionRoll))\n",
    "    fv.append(np.std(motionRoll))\n",
    "    motionPitch = sample[:,14]\n",
    "    fv.append(np.min(motionPitch))\n",
    "    motionRotationRateX = sample[:,15]\n",
    "    motionRotationRateY = sample[:,16]\n",
    "    motionRotationRateZ = sample[:,17]\n",
    "    \n",
    "#     'motionYaw(rad)',\n",
    "#     'motionRoll(rad)',\n",
    "#     'motionPitch(rad)',\n",
    "#     'motionRotationRateX(rad/s)',\n",
    "#     'motionRotationRateY(rad/s)',\n",
    "#     'motionRotationRateZ(rad/s)',\n",
    "#     'motionUserAccelerationX(G)',\n",
    "#     'motionUserAccelerationY(G)',\n",
    "#     'motionUserAccelerationZ(G)',\n",
    "    \n",
    "    fv = []\n",
    "    sample = np.asarray(acc_total)\n",
    "\n",
    "    # extremes\n",
    "    fv.append(np.max(acc_total))\n",
    "    fv.append(np.max(gyro_total))\n",
    "    fv.append(np.max(loc_speed))\n",
    "    fv.append(np.max(altimeter))\n",
    "    \n",
    "    # I noticed this helps w/ differentiating climbing\n",
    "    fv.append(np.max(gyro_x))\n",
    "    fv.append(np.max(gyro_y))\n",
    "    fv.append(np.max(gyro_z))\n",
    "\n",
    "    # averages\n",
    "    fv.append(np.mean(acc_total))\n",
    "    fv.append(np.mean(gyro_total))\n",
    "    fv.append(np.mean(loc_speed))\n",
    "    fv.append(np.mean(acc_x))\n",
    "    fv.append(np.mean(acc_y))\n",
    "    fv.append(np.mean(acc_z))\n",
    "    fv.append(np.mean(gyro_x))\n",
    "    fv.append(np.mean(gyro_y))\n",
    "    fv.append(np.mean(gyro_z))\n",
    "    \n",
    "    fv.append(np.median(acc_total))\n",
    "    fv.append(np.median(gyro_total))\n",
    "    fv.append(np.median(loc_speed))\n",
    "    \n",
    "\n",
    "    # deviation\n",
    "    fv.append(np.std(acc_total))\n",
    "    fv.append(np.std(gyro_total))\n",
    "    fv.append(np.std(loc_speed))\n",
    "    fv.append(np.std(altimeter))\n",
    "    \n",
    "    # Peak-to-peak\n",
    "    # Rootmean-square\n",
    "    # Correlation between values of accelerometer and gyroscope axes are extracted\n",
    "    \n",
    "    fv = np.asarray(fv)\n",
    "    return fv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose if featuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167, 23)\n",
      "(167,)\n"
     ]
    }
   ],
   "source": [
    "windowing = False\n",
    "X_processed, Y_adjusted, groups = process_input(X, Y, windowing)\n",
    "print(X_processed.shape)\n",
    "print(Y_adjusted.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scaler = RobustScaler()\n",
    "X = scaler.fit_transform(X_processed) # this normalizes well\n",
    "import seaborn as sns\n",
    "print(X.shape[1])\n",
    "for i in range(X.shape[1]):\n",
    "    sns.kdeplot(X[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 23) (133, 5) (34, 23) (34, 5)\n",
      "Epoch 1/133\n",
      "133/133 [==============================] - 0s 645us/step - loss: 3.0722 - accuracy: 0.2406\n",
      "Epoch 2/133\n",
      "133/133 [==============================] - 0s 291us/step - loss: 2.3346 - accuracy: 0.3008\n",
      "Epoch 3/133\n",
      "133/133 [==============================] - 0s 389us/step - loss: 1.8713 - accuracy: 0.3609\n",
      "Epoch 4/133\n",
      "133/133 [==============================] - 0s 397us/step - loss: 1.5916 - accuracy: 0.4060\n",
      "Epoch 5/133\n",
      "133/133 [==============================] - 0s 267us/step - loss: 1.4556 - accuracy: 0.4737\n",
      "Epoch 6/133\n",
      "133/133 [==============================] - 0s 542us/step - loss: 1.3825 - accuracy: 0.4812\n",
      "Epoch 7/133\n",
      "133/133 [==============================] - 0s 184us/step - loss: 1.3273 - accuracy: 0.5714\n",
      "Epoch 8/133\n",
      "133/133 [==============================] - 0s 270us/step - loss: 1.2880 - accuracy: 0.5564\n",
      "Epoch 9/133\n",
      "133/133 [==============================] - 0s 201us/step - loss: 1.2547 - accuracy: 0.5789\n",
      "Epoch 10/133\n",
      "133/133 [==============================] - 0s 309us/step - loss: 1.2310 - accuracy: 0.5489\n",
      "Epoch 11/133\n",
      "133/133 [==============================] - 0s 231us/step - loss: 1.2103 - accuracy: 0.5940\n",
      "Epoch 12/133\n",
      "133/133 [==============================] - 0s 190us/step - loss: 1.1912 - accuracy: 0.6090\n",
      "Epoch 13/133\n",
      "133/133 [==============================] - 0s 233us/step - loss: 1.1765 - accuracy: 0.5940\n",
      "Epoch 14/133\n",
      "133/133 [==============================] - 0s 174us/step - loss: 1.1560 - accuracy: 0.5865\n",
      "Epoch 15/133\n",
      "133/133 [==============================] - 0s 146us/step - loss: 1.1480 - accuracy: 0.5489\n",
      "Epoch 16/133\n",
      "133/133 [==============================] - 0s 279us/step - loss: 1.1317 - accuracy: 0.6090\n",
      "Epoch 17/133\n",
      "133/133 [==============================] - 0s 168us/step - loss: 1.1206 - accuracy: 0.6241\n",
      "Epoch 18/133\n",
      "133/133 [==============================] - 0s 189us/step - loss: 1.1169 - accuracy: 0.6466\n",
      "Epoch 19/133\n",
      "133/133 [==============================] - 0s 228us/step - loss: 1.1022 - accuracy: 0.6090\n",
      "Epoch 20/133\n",
      "133/133 [==============================] - 0s 207us/step - loss: 1.0941 - accuracy: 0.6090\n",
      "Epoch 21/133\n",
      "133/133 [==============================] - 0s 182us/step - loss: 1.0895 - accuracy: 0.5865\n",
      "Epoch 22/133\n",
      "133/133 [==============================] - 0s 311us/step - loss: 1.0789 - accuracy: 0.5714\n",
      "Epoch 23/133\n",
      "133/133 [==============================] - 0s 309us/step - loss: 1.0755 - accuracy: 0.6541\n",
      "Epoch 24/133\n",
      "133/133 [==============================] - 0s 366us/step - loss: 1.0634 - accuracy: 0.6090\n",
      "Epoch 25/133\n",
      "133/133 [==============================] - 0s 279us/step - loss: 1.0593 - accuracy: 0.5940\n",
      "Epoch 26/133\n",
      "133/133 [==============================] - 0s 191us/step - loss: 1.0521 - accuracy: 0.6617\n",
      "Epoch 27/133\n",
      "133/133 [==============================] - 0s 248us/step - loss: 1.0459 - accuracy: 0.6165\n",
      "Epoch 28/133\n",
      "133/133 [==============================] - 0s 192us/step - loss: 1.0430 - accuracy: 0.6617\n",
      "Epoch 29/133\n",
      "133/133 [==============================] - 0s 319us/step - loss: 1.0402 - accuracy: 0.6241\n",
      "Epoch 30/133\n",
      "133/133 [==============================] - 0s 176us/step - loss: 1.0323 - accuracy: 0.6391\n",
      "Epoch 31/133\n",
      "133/133 [==============================] - 0s 290us/step - loss: 1.0268 - accuracy: 0.7218\n",
      "Epoch 32/133\n",
      "133/133 [==============================] - 0s 197us/step - loss: 1.0224 - accuracy: 0.6316\n",
      "Epoch 33/133\n",
      "133/133 [==============================] - 0s 344us/step - loss: 1.0203 - accuracy: 0.6617\n",
      "Epoch 34/133\n",
      "133/133 [==============================] - 0s 222us/step - loss: 1.0130 - accuracy: 0.6316\n",
      "Epoch 35/133\n",
      "133/133 [==============================] - 0s 221us/step - loss: 1.0090 - accuracy: 0.6541\n",
      "Epoch 36/133\n",
      "133/133 [==============================] - 0s 357us/step - loss: 1.0048 - accuracy: 0.6992\n",
      "Epoch 37/133\n",
      "133/133 [==============================] - 0s 266us/step - loss: 1.0018 - accuracy: 0.6090\n",
      "Epoch 38/133\n",
      "133/133 [==============================] - 0s 307us/step - loss: 0.9949 - accuracy: 0.6617\n",
      "Epoch 39/133\n",
      "133/133 [==============================] - 0s 248us/step - loss: 0.9972 - accuracy: 0.6992\n",
      "Epoch 40/133\n",
      "133/133 [==============================] - 0s 262us/step - loss: 0.9922 - accuracy: 0.6391\n",
      "Epoch 41/133\n",
      "133/133 [==============================] - 0s 229us/step - loss: 0.9892 - accuracy: 0.6992\n",
      "Epoch 42/133\n",
      "133/133 [==============================] - 0s 207us/step - loss: 0.9843 - accuracy: 0.6692\n",
      "Epoch 43/133\n",
      "133/133 [==============================] - 0s 258us/step - loss: 0.9743 - accuracy: 0.6316\n",
      "Epoch 44/133\n",
      "133/133 [==============================] - 0s 166us/step - loss: 0.9702 - accuracy: 0.6316\n",
      "Epoch 45/133\n",
      "133/133 [==============================] - 0s 273us/step - loss: 0.9706 - accuracy: 0.6617\n",
      "Epoch 46/133\n",
      "133/133 [==============================] - 0s 306us/step - loss: 0.9641 - accuracy: 0.6466\n",
      "Epoch 47/133\n",
      "133/133 [==============================] - 0s 257us/step - loss: 0.9648 - accuracy: 0.6466\n",
      "Epoch 48/133\n",
      "133/133 [==============================] - 0s 264us/step - loss: 0.9611 - accuracy: 0.6692\n",
      "Epoch 49/133\n",
      "133/133 [==============================] - 0s 303us/step - loss: 0.9572 - accuracy: 0.6842\n",
      "Epoch 50/133\n",
      "133/133 [==============================] - 0s 339us/step - loss: 0.9477 - accuracy: 0.6917\n",
      "Epoch 51/133\n",
      "133/133 [==============================] - 0s 229us/step - loss: 0.9500 - accuracy: 0.6541\n",
      "Epoch 52/133\n",
      "133/133 [==============================] - 0s 302us/step - loss: 0.9428 - accuracy: 0.7143\n",
      "Epoch 53/133\n",
      "133/133 [==============================] - 0s 261us/step - loss: 0.9419 - accuracy: 0.6165\n",
      "Epoch 54/133\n",
      "133/133 [==============================] - 0s 350us/step - loss: 0.9371 - accuracy: 0.6767\n",
      "Epoch 55/133\n",
      "133/133 [==============================] - 0s 271us/step - loss: 0.9374 - accuracy: 0.6917\n",
      "Epoch 56/133\n",
      "133/133 [==============================] - 0s 282us/step - loss: 0.9309 - accuracy: 0.6917\n",
      "Epoch 57/133\n",
      "133/133 [==============================] - 0s 322us/step - loss: 0.9344 - accuracy: 0.6617\n",
      "Epoch 58/133\n",
      "133/133 [==============================] - 0s 273us/step - loss: 0.9334 - accuracy: 0.6692\n",
      "Epoch 59/133\n",
      "133/133 [==============================] - 0s 293us/step - loss: 0.9204 - accuracy: 0.6466\n",
      "Epoch 60/133\n",
      "133/133 [==============================] - 0s 218us/step - loss: 0.9300 - accuracy: 0.6391\n",
      "Epoch 61/133\n",
      "133/133 [==============================] - 0s 244us/step - loss: 0.9168 - accuracy: 0.7218\n",
      "Epoch 62/133\n",
      "133/133 [==============================] - 0s 273us/step - loss: 0.9192 - accuracy: 0.6617\n",
      "Epoch 63/133\n",
      "133/133 [==============================] - 0s 293us/step - loss: 0.9098 - accuracy: 0.6692\n",
      "Epoch 64/133\n",
      "133/133 [==============================] - 0s 296us/step - loss: 0.9129 - accuracy: 0.6617\n",
      "Epoch 65/133\n",
      "133/133 [==============================] - 0s 314us/step - loss: 0.9086 - accuracy: 0.6617\n",
      "Epoch 66/133\n",
      "133/133 [==============================] - 0s 337us/step - loss: 0.9038 - accuracy: 0.6617\n",
      "Epoch 67/133\n",
      "133/133 [==============================] - 0s 263us/step - loss: 0.9020 - accuracy: 0.6917\n",
      "Epoch 68/133\n",
      "133/133 [==============================] - 0s 272us/step - loss: 0.8998 - accuracy: 0.6767\n",
      "Epoch 69/133\n",
      "133/133 [==============================] - 0s 189us/step - loss: 0.8971 - accuracy: 0.6391\n",
      "Epoch 70/133\n",
      "133/133 [==============================] - 0s 234us/step - loss: 0.8884 - accuracy: 0.6617\n",
      "Epoch 71/133\n",
      "133/133 [==============================] - 0s 316us/step - loss: 0.8888 - accuracy: 0.6692\n",
      "Epoch 72/133\n",
      "133/133 [==============================] - 0s 554us/step - loss: 0.8892 - accuracy: 0.6466\n",
      "Epoch 73/133\n",
      "133/133 [==============================] - 0s 258us/step - loss: 0.8820 - accuracy: 0.7143\n",
      "Epoch 74/133\n",
      "133/133 [==============================] - 0s 251us/step - loss: 0.8857 - accuracy: 0.6767\n",
      "Epoch 75/133\n",
      "133/133 [==============================] - 0s 187us/step - loss: 0.8830 - accuracy: 0.6917\n",
      "Epoch 76/133\n",
      "133/133 [==============================] - 0s 260us/step - loss: 0.8792 - accuracy: 0.6767\n",
      "Epoch 77/133\n",
      "133/133 [==============================] - 0s 260us/step - loss: 0.8775 - accuracy: 0.6917\n",
      "Epoch 78/133\n",
      "133/133 [==============================] - 0s 224us/step - loss: 0.8698 - accuracy: 0.6466\n",
      "Epoch 79/133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 0s 256us/step - loss: 0.8707 - accuracy: 0.6692\n",
      "Epoch 80/133\n",
      "133/133 [==============================] - 0s 796us/step - loss: 0.8694 - accuracy: 0.7143\n",
      "Epoch 81/133\n",
      "133/133 [==============================] - 0s 319us/step - loss: 0.8607 - accuracy: 0.7068\n",
      "Epoch 82/133\n",
      "133/133 [==============================] - 0s 262us/step - loss: 0.8656 - accuracy: 0.6992\n",
      "Epoch 83/133\n",
      "133/133 [==============================] - 0s 280us/step - loss: 0.8578 - accuracy: 0.6541\n",
      "Epoch 84/133\n",
      "133/133 [==============================] - 0s 213us/step - loss: 0.8626 - accuracy: 0.6842\n",
      "Epoch 85/133\n",
      "133/133 [==============================] - 0s 184us/step - loss: 0.8553 - accuracy: 0.6917\n",
      "Epoch 86/133\n",
      "133/133 [==============================] - 0s 240us/step - loss: 0.8459 - accuracy: 0.6842\n",
      "Epoch 87/133\n",
      "133/133 [==============================] - 0s 192us/step - loss: 0.8491 - accuracy: 0.7218\n",
      "Epoch 88/133\n",
      "133/133 [==============================] - 0s 234us/step - loss: 0.8475 - accuracy: 0.6917\n",
      "Epoch 89/133\n",
      "133/133 [==============================] - 0s 231us/step - loss: 0.8382 - accuracy: 0.7368\n",
      "Epoch 90/133\n",
      "133/133 [==============================] - 0s 217us/step - loss: 0.8427 - accuracy: 0.7143\n",
      "Epoch 91/133\n",
      "133/133 [==============================] - 0s 262us/step - loss: 0.8416 - accuracy: 0.6842\n",
      "Epoch 92/133\n",
      "133/133 [==============================] - 0s 462us/step - loss: 0.8322 - accuracy: 0.6917\n",
      "Epoch 93/133\n",
      "133/133 [==============================] - 0s 412us/step - loss: 0.8352 - accuracy: 0.7218\n",
      "Epoch 94/133\n",
      "133/133 [==============================] - 0s 297us/step - loss: 0.8267 - accuracy: 0.6992\n",
      "Epoch 95/133\n",
      "133/133 [==============================] - 0s 257us/step - loss: 0.8204 - accuracy: 0.7293\n",
      "Epoch 96/133\n",
      "133/133 [==============================] - 0s 276us/step - loss: 0.8286 - accuracy: 0.7293\n",
      "Epoch 97/133\n",
      "133/133 [==============================] - 0s 249us/step - loss: 0.8178 - accuracy: 0.7293\n",
      "Epoch 98/133\n",
      "133/133 [==============================] - 0s 202us/step - loss: 0.8170 - accuracy: 0.7143\n",
      "Epoch 99/133\n",
      "133/133 [==============================] - 0s 286us/step - loss: 0.8160 - accuracy: 0.7218\n",
      "Epoch 100/133\n",
      "133/133 [==============================] - 0s 401us/step - loss: 0.8109 - accuracy: 0.7218\n",
      "Epoch 101/133\n",
      "133/133 [==============================] - 0s 246us/step - loss: 0.8082 - accuracy: 0.7293\n",
      "Epoch 102/133\n",
      "133/133 [==============================] - 0s 249us/step - loss: 0.8037 - accuracy: 0.7143\n",
      "Epoch 103/133\n",
      "133/133 [==============================] - 0s 336us/step - loss: 0.7972 - accuracy: 0.6767\n",
      "Epoch 104/133\n",
      "133/133 [==============================] - 0s 241us/step - loss: 0.8040 - accuracy: 0.7293\n",
      "Epoch 105/133\n",
      "133/133 [==============================] - 0s 247us/step - loss: 0.7940 - accuracy: 0.7218\n",
      "Epoch 106/133\n",
      "133/133 [==============================] - 0s 359us/step - loss: 0.7923 - accuracy: 0.7594\n",
      "Epoch 107/133\n",
      "133/133 [==============================] - 0s 380us/step - loss: 0.7913 - accuracy: 0.7368\n",
      "Epoch 108/133\n",
      "133/133 [==============================] - 0s 204us/step - loss: 0.7877 - accuracy: 0.7143\n",
      "Epoch 109/133\n",
      "133/133 [==============================] - 0s 169us/step - loss: 0.7869 - accuracy: 0.7218\n",
      "Epoch 110/133\n",
      "133/133 [==============================] - 0s 170us/step - loss: 0.7825 - accuracy: 0.7519\n",
      "Epoch 111/133\n",
      "133/133 [==============================] - 0s 173us/step - loss: 0.7804 - accuracy: 0.7519\n",
      "Epoch 112/133\n",
      "133/133 [==============================] - 0s 210us/step - loss: 0.7768 - accuracy: 0.7368\n",
      "Epoch 113/133\n",
      "133/133 [==============================] - 0s 185us/step - loss: 0.7748 - accuracy: 0.7368\n",
      "Epoch 114/133\n",
      "133/133 [==============================] - 0s 278us/step - loss: 0.7732 - accuracy: 0.7444\n",
      "Epoch 115/133\n",
      "133/133 [==============================] - 0s 296us/step - loss: 0.7723 - accuracy: 0.7368\n",
      "Epoch 116/133\n",
      "133/133 [==============================] - 0s 276us/step - loss: 0.7719 - accuracy: 0.7744\n",
      "Epoch 117/133\n",
      "133/133 [==============================] - 0s 234us/step - loss: 0.7586 - accuracy: 0.7744\n",
      "Epoch 118/133\n",
      "133/133 [==============================] - 0s 170us/step - loss: 0.7607 - accuracy: 0.7594\n",
      "Epoch 119/133\n",
      "133/133 [==============================] - 0s 560us/step - loss: 0.7552 - accuracy: 0.7594\n",
      "Epoch 120/133\n",
      "133/133 [==============================] - 0s 238us/step - loss: 0.7591 - accuracy: 0.7519\n",
      "Epoch 121/133\n",
      "133/133 [==============================] - 0s 235us/step - loss: 0.7538 - accuracy: 0.7744\n",
      "Epoch 122/133\n",
      "133/133 [==============================] - 0s 258us/step - loss: 0.7436 - accuracy: 0.7594\n",
      "Epoch 123/133\n",
      "133/133 [==============================] - 0s 230us/step - loss: 0.7562 - accuracy: 0.7519\n",
      "Epoch 124/133\n",
      "133/133 [==============================] - 0s 307us/step - loss: 0.7485 - accuracy: 0.7594\n",
      "Epoch 125/133\n",
      "133/133 [==============================] - 0s 324us/step - loss: 0.7429 - accuracy: 0.7594\n",
      "Epoch 126/133\n",
      "133/133 [==============================] - 0s 269us/step - loss: 0.7453 - accuracy: 0.7744\n",
      "Epoch 127/133\n",
      "133/133 [==============================] - 0s 285us/step - loss: 0.7396 - accuracy: 0.7519\n",
      "Epoch 128/133\n",
      "133/133 [==============================] - 0s 261us/step - loss: 0.7315 - accuracy: 0.7744\n",
      "Epoch 129/133\n",
      "133/133 [==============================] - 0s 264us/step - loss: 0.7335 - accuracy: 0.7519\n",
      "Epoch 130/133\n",
      "133/133 [==============================] - 0s 325us/step - loss: 0.7320 - accuracy: 0.7444\n",
      "Epoch 131/133\n",
      "133/133 [==============================] - 0s 296us/step - loss: 0.7281 - accuracy: 0.7594\n",
      "Epoch 132/133\n",
      "133/133 [==============================] - 0s 317us/step - loss: 0.7241 - accuracy: 0.7669\n",
      "Epoch 133/133\n",
      "133/133 [==============================] - 0s 223us/step - loss: 0.7269 - accuracy: 0.7594\n",
      "[[0.137 0.019 0.811 0.007 0.027]\n",
      " [0.002 0.655 0.16  0.001 0.183]\n",
      " [0.1   0.174 0.327 0.268 0.131]\n",
      " [0.716 0.024 0.112 0.111 0.036]\n",
      " [0.546 0.03  0.315 0.059 0.051]\n",
      " [0.    0.124 0.042 0.    0.834]\n",
      " [0.    0.44  0.161 0.    0.399]\n",
      " [0.006 0.046 0.015 0.926 0.007]\n",
      " [0.683 0.028 0.084 0.16  0.045]\n",
      " [0.07  0.093 0.753 0.005 0.079]\n",
      " [0.005 0.059 0.014 0.916 0.006]\n",
      " [0.66  0.021 0.244 0.042 0.032]\n",
      " [0.014 0.014 0.01  0.956 0.006]\n",
      " [0.812 0.018 0.104 0.042 0.024]\n",
      " [0.57  0.035 0.225 0.101 0.07 ]\n",
      " [0.    0.329 0.069 0.    0.601]\n",
      " [0.    0.363 0.271 0.    0.366]\n",
      " [0.172 0.101 0.215 0.467 0.046]\n",
      " [0.    0.44  0.069 0.    0.491]\n",
      " [0.    0.954 0.013 0.03  0.003]\n",
      " [0.436 0.032 0.118 0.373 0.042]\n",
      " [0.004 0.048 0.01  0.931 0.006]\n",
      " [0.    0.007 0.986 0.    0.007]\n",
      " [0.    0.398 0.083 0.    0.519]\n",
      " [0.638 0.022 0.228 0.072 0.041]\n",
      " [0.    0.415 0.315 0.    0.27 ]\n",
      " [0.    0.324 0.461 0.    0.215]\n",
      " [0.    0.595 0.09  0.    0.315]\n",
      " [0.704 0.028 0.082 0.149 0.037]\n",
      " [0.773 0.02  0.11  0.07  0.027]\n",
      " [0.178 0.192 0.035 0.492 0.104]\n",
      " [0.    0.389 0.076 0.    0.535]\n",
      " [1.    0.    0.    0.    0.   ]\n",
      " [0.076 0.14  0.03  0.667 0.087]]\n",
      "[[0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]]\n",
      "34/34 [==============================] - 0s 1ms/step\n",
      "score is:  [9.07459257630741, 0.5588235259056091]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from numpy import load\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    " \n",
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "    # separate into train and test datasets\n",
    "    trainX, testX, trainY, testY = train_test_split(X_processed, to_categorical(Y_adjusted), test_size=0.2, random_state=10)\n",
    "    print(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "    return trainX, trainY, testX, testY\n",
    " \n",
    "# calculate fbeta score for multi-class/label classification\n",
    "def fbeta(y_true, y_pred, beta=2):\n",
    "    # clip predictions\n",
    "    y_pred = backend.clip(y_pred, 0, 1)\n",
    "    # calculate elements\n",
    "    tp = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)), axis=1)\n",
    "    fp = backend.sum(backend.round(backend.clip(y_pred - y_true, 0, 1)), axis=1)\n",
    "    fn = backend.sum(backend.round(backend.clip(y_true - y_pred, 0, 1)), axis=1)\n",
    "    # calculate precision\n",
    "    p = tp / (tp + fp + backend.epsilon())\n",
    "    # calculate recall\n",
    "    r = tp / (tp + fn + backend.epsilon())\n",
    "    # calculate fbeta, averaged across each class\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = backend.mean((1 + bb) * (p * r) / (bb * p + r + backend.epsilon()))\n",
    "    return fbeta_score\n",
    " \n",
    "# define cnn model\n",
    "def define_model(trainX):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "    opt = SGD(lr=0.01, momentum=0.9)\n",
    "    model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    " \n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "    # plot loss\n",
    "    pyplot.subplot(211)\n",
    "    pyplot.title('Cross Entropy Loss')\n",
    "    pyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "    # plot accuracy\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Fbeta')\n",
    "    pyplot.plot(history.history['fbeta'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_fbeta'], color='orange', label='test')\n",
    "    # save plot to file\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    pyplot.savefig(filename + '_plot.png')\n",
    "    pyplot.close()\n",
    " \n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "\n",
    "    model = define_model(trainX)\n",
    "        \n",
    "    model.fit(trainX, trainY, batch_size=8, epochs=len(trainY))\n",
    "    \n",
    "    \n",
    "    predicted = model.predict(testX, batch_size=8, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=True)\n",
    "    \n",
    "    print(np.around(predicted, decimals=3, out=None))\n",
    "    print(testY)\n",
    "    score = model.evaluate(testX, testY, batch_size=8)\n",
    "    \n",
    "    print(\"score is: \", score)\n",
    "#     print(testY)\n",
    "#     print('test x is: ', testX)\n",
    " \n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
